# Containerization and Orchestration for Research Reproducibility

This repository contains code for **Containerization and Orchestration for Research Reproducibility** focused on benchmarking Large Language Models (LLMs) for mathematical reasoning tasks.

## Key Features:
- All experiments are dockerized and can be easily executed using Docker Compose.
- Results are saved in a dedicated folder on the host machine for easy access.
- Experiment parameters are fully configurable through environment variables.
- The script detects previously executed experiments with the same parameter configuration and skips redundant runs.

---

## Preliminaries & Quick Start

- The project uses a Docker image based on `nvidia/cuda:12.3.2-devel-ubuntu22.04`.
- A minimum of two GPU devices is required to run the experiments.
- To get started, run the following command to build and start the Docker containers:

```bash
docker-compose up --build
```

## Project Overview

This project benchmarks Large Language Models (LLMs) on mathematical reasoning tasks, specifically evaluating the performance of **Qwen2.5-Math-1.5B-Instruct** on the **GSM8K** benchmark.

### Evaluation Methodology:
We assess the model using two common inference techniques for mathematical reasoning tasks:

1. **Greedy Chain-of-Thought**: The model is prompted to generate a **single** step-by-step reasoning sequence with temperature set to 0, ensuring that the model always outputs the most confident reasoning at each step.

2. **Self-Consistency Chain-of-Thought**: Here, the model generates **multiple** step-by-step reasoning sequences. A majority voting mechanism is then applied to select the most consistent final answer, leveraging the idea that considering multiple reasoning paths often yields a more reliable result.

### Objective:
The primary goal is to verify whether **Self-Consistency Chain-of-Thought** results in higher performance compared to **Greedy Chain-of-Thought**, as it often leads to more robust outcomes in reasoning tasks. 

### vLLM

We use the widely-used **vLLM** library to run evaluations with the LLM. vLLM is a fast and easy-to-use library designed for LLM inference and serving, integrating with popular Hugging Face models. It supports high-throughput serving with various decoding algorithms, including batch decoding, which significantly speeds up inference.

However, the library does not support running multiple instances of the process on the same device. As a result, experiments are split across two separate GPUs: one GPU is used for **Greedy CoT** and the other for **Self-CoT**.

This is achieved in the `docker-compose` file by adding the following lines to specify the device type and ID:

```python
# for experiment 1
deploy:
  resources:
    reservations:
      devices:
        - capabilities: [ gpu ]
          device_ids: [ "0" ]

# for experiment 2
deploy:
  resources:
    reservations:
      devices:
        - capabilities: [ gpu ]
          device_ids: [ "1" ]
```

*NOTES*:
- *Limitations*: The number of experiments that can be run in parallel depends on the number of available GPUs. In this setup, the experiment is limited to running on two GPUs, one for each decoding modality (CoT or Self-CoT).
- *Extensibility*: The project can be easily extended to consider additional configurations, such as:
  - Multiple LLMs as baselines.
  - Multiple benchmarks for broader evaluation.
  - Various decoding settings for the Self-CoT modality (e.g., different temperature or top-p values).

### Environment Parameters

These are the available parameters that can be set for each experiment:

- `RANDOM_STATE`: The random seed used for experiment reproducibility.
- `MODEL_ID`: The HuggingFace repo ID of the model to use.
- `MODE`: The mode for running the experiment (e.g., "cot" for *Greedy* or "self-cot" for *Self-consistency*).
- `TEMPERATURE`: The temperature value for sampling. 0 for Greedy, while usually > 0.5 for Self-CoT.
- `TOP_P`: The top-p value for nucleus sampling. Default is 0.8.
- `TEST_SIZE`: The proportion of the dataset to be used for testing.
- `BATCH_SIZE`: The number of examples to process in each batch.
- `N_OUTPUTS`: The number of outputs to generate from the model. 1 for Greedy, while > 1 for Self-CoT.

### Outputs
The results of the experiments runned are stored in the `OUTPUT_DIR` defined in the enviroment. Particullay for each experiment two files are generated:

1) `out_{MODE}.jsonl` to store all the completions generated by the LLM.
```
{"gold_answer": "18", "final_answer": "18", "reasoning": "To determine how much Janet makes every day at the farmers' market, we need to follow these steps:\n\n1. Calculate the total number of eggs laid by the ducks each day.\n2. Determine how many eggs Janet uses for breakfast and baking muffins.\n3. Find out how many eggs are left for sale.\n4. Calculate the revenue from selling the remaining eggs.\n\nStep 1: Calculate the total number of eggs laid by the ducks each day.\nJanet's ducks lay 16 eggs per day.\n\nStep 2: Determine how many eggs Janet uses for breakfast and baking muffins.\nJanet eats 3 eggs for breakfast every morning and bakes 4 eggs for her friends every day. So, the total number of eggs used each day is:\n\\[ 3 + 4 = 7 \\text{ eggs} \\]\n\nStep 3: Find out how many eggs are left for sale.\nSubtract the number of eggs used from the total number of eggs laid:\n\\[ 16 - 7 = 9 \\text{ eggs} \\]\n\nStep 4: Calculate the revenue from selling the remaining eggs.\nJanet sells each remaining egg for $2. So, the revenue from selling 9 eggs is:\n\\[ 9 \\times 2 = 18 \\text{ dollars} \\]\n\nTherefore, Janet makes \\(\\boxed{18}\\) dollars every day at the farmers' market."}
{"gold_answer": "3", "final_answer": "3", "reasoning": "To determine the total number of bolts of fiber the boxed takes, we need to follow these steps:\n\n1. Identify the number of bolts of blue fiber the boxed takes. According to the problem, the boxed takes 2 bolts of blue fiber.\n2. Determine the number of bolts of white fiber the boxed takes. The problem states that the boxed takes half as much white fiber as blue fiber. Since the boxed takes 2 bolts of blue fiber, it takes \\(\\frac{2}{2} = 1\\) bolt of white fiber.\n3. Calculate the total number of bolts of fiber by adding the number of bolts of blue fiber and the number of bolts of white fiber. This gives us \\(2 + 1 = 3\\).\n\nTherefore, the total number of bolts of fiber the boxed takes is \\(\\boxed{3}\\)."}
{"gold_answer": "70000", "final_answer": "120000", "reasoning": "To determine the profit Josh made, we need to follow these steps:\n\n1. Calculate the total cost of the house after repairs.\n2. Determine the increased value of the house after the repairs.\n3. Calculate the profit by subtracting the total cost from the increased value.\n\n**Step 1: Calculate the total cost of the house after repairs.**\n\nThe original cost of the house is $80,000. Josh spends an additional $50,000 on repairs. Therefore, the total cost is:\n\\[ 80,000 + 50,000 = 130,000 \\]\n\n**Step 2: Determine the increased value of the house after the repairs.**\n\nThe repairs increased the value of the house by 150%. This means the increased value is 150% of the original cost of the house plus the cost of the repairs. First, we need to find 150% of the original cost of the house:\n\\[ 150\\% \\text{ of } 80,000 = 1.5 \\times 80,000 = 120,000 \\]\n\nThe increased value of the house is the original cost plus the cost of the repairs plus the increase in value:\n\\[ 80,000 + 50,000 + 120,000 = 250,000 \\]\n\n**Step 3: Calculate the profit.**\n\nThe profit is the increased value of the house minus the total cost:\n\\[ 250,000 - 130,000 = 120,000 \\]\n\nTherefore, the profit Josh made is:\n\\[ \\boxed{120000} \\]"}
...
```

2) `accuracy.txt` to store the final accuracy obtained by the LLM.
```
Experiment ID: 04b641a8ebd9409017b1d07825cd8f26b09b124bdfe854751e775bb05b39a58fde654540955f66fe79150858199ac24b6f911478d4f969ff87463b22a470b87d
Accuracy: 83.0
----------------------
```


